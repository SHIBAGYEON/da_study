# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NXaKgWTF7Jk7dThUIMpANiMT2paetDiQ
"""

from sklearn.tree import DecisionTreeClassifier

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

df =sns.load_dataset('titanic')
df.head()

df.describe()
 
df.info()

train_df = df[:800]
test_df = df[800:]

train_df[['pclass', 'survived']].groupby(['pclass'], as_index=False).mean().sort_values(by='survived', ascending=False)

train_df[['sex', 'survived']].groupby(['sex'], as_index=False).mean().sort_values(by='survived', ascending=False)

train_df[['parch', 'survived']].groupby(['parch'], as_index=False).mean().sort_values(by='survived', ascending=False)

sns.histplot(data = train_df, x = 'age',bins = 20, hue = 'survived')

a = sns.FacetGrid(train_df, col='survived')
a.map(plt.hist, 'age', bins=20)

names = train_df.columns

train_df = train_df.drop(names[4:], axis=1)

train_df.head()

train_df.isnull().sum()
test_df.isnull().sum()

map_dict = {'femaie' : 0, 'maie' : 1}

a = sns.FacetGrid(train_df, col='survived', row='pclass')
a.map(plt.hist, 'age', bins=20)

names = train_df.columns
print(names)

train_df = train_df.drop(names[4:], axis=1)
test_df = test_df.drop(names[4:], axis=1)

train_df.head()

print(train_df.isnull().sum())
print(test_df.isnull().sum())

train_df.fillna(train_df.mean()[['age']], inplace = True)
test_df.fillna(test_df.mean()[['age']], inplace = True)

print(train_df.isnull().sum())
print(test_df.isnull().sum())

map_dict = {'female' : 0, 'male' : 1}
train_df['sex'] = train_df['sex'].map(map_dict).astype(int)
test_df['sex'] = test_df['sex'].map(map_dict).astype(int)

train_df.head()

def fuction1(x):
  if x < 20:
    return 1
  elif x < 40:
    return 2
  elif x < 60:
    return 3
  else:
    return 4

train_df['age'] = train_df['age'].apply(fuction1)
test_df['age'] = test_df['age'].apply(fuction1)

train_df.head()

"""### **3.머신러닝 모델 구성 및 결과 검증**"""

X_train = train_df.drop(["survived"], axis=1)
Y_train = train_df["survived"]
X_test = test_df.drop(["survived"], axis=1)
Y_test = test_df["survived"]

X_train.head()
Y_train.head()

decition_tree = DecisionTreeClassifier()
decition_tree.fit(X_train, Y_train)

#decition_tree2 = DecisionTreeClassifier()
#decition_tree2.fit(X_test, Y_test)
X_test.head()
Y_test.head()
print(X_test)

print(decition_tree.score(X_train, Y_train))
#print(decition_tree.score(X_test, Y_test))

Y_pred = decition_tree.predict(X_train)
print(Y_pred)

len(Y_pred)

Y_test_list = list(Y_train)
Y_pred[0]

total = 0
for i in range(len(Y_pred)):
  if Y_pred[i] == Y_test_list[i]:
    total += 1
  else:
    pass
print(total)
print(total/len(Y_pred))