# CH02_02. Linear Regression 심화

'''
1. Multivariate Regression
-다변량 회귀: 두 개 이상의 변수로 만든 회귀식
-수식
변수가 2개인 경우: y=b0+b1x1+b2x2
변수가 3개인 경우: y=b0+b1x1+b2x2
변수가 여러 개인 경우: 행렬로 표시

2. Polynomial Regression
-다항식 회귀: 예측하는 값이 선형이 아닌 비선형일 경우 사용
-직선이 아니고 곡선이므로 x^2, x^3, ... 변수가 존재
-수식: y=b0+b1x1+b2x^2 (일반형을 표준형으로 변형하여 그래프 확인)

3. 회귀 계수를 계산하는 방법
1) 통계적 방법
-최소제곱법(MSE)으로 구한 b=(X^TX)^(-1)X^Ty

2) ML 방법
-여러 값을 넣어본 뒤 loss(MSE)가 제일 작은 b를 찾는다 -> 최적화 알고리즘
-최적화 알고리즘: Bisection Method, Gradient Descent
-Bisection Method
 (1) 임의의 두 개의 값을 설정
 (2) 두 값의 y값을 비교
 (3) y값이 큰 점을 두 점의 가운데 점으로 바꾼다
 (4) 임의의 두 값의 차이가 작아질 때까지 (1)~(3)을 반복

-Gradient Descent
: 함수의 기울기(경사)를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜
극값에 이를 때까지 반복시키는 것
 (1) 임의의 값 하나를 설정
 (2) 임의의 값에서의 기울기를 계산
 (3) 기울기와 Learning rate를 곱한 값을 임의의 값에서 뺀다
 (4) 기울기가 0에 가까워질 때까지 (1)~(3)을 뺀다
'''